{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"TensorFlow 2.2 on Python 3.6 (CUDA 10.1)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"nav_menu":{"height":"252px","width":"333px"},"toc":{"navigate_menu":true,"number_sections":true,"sideBar":true,"threshold":6,"toc_cell":false,"toc_section_display":"block","toc_window_display":false},"colab":{"name":"Copy of 07_ensemble_learning_and_random_forests.ipynb의 사본","provenance":[{"file_id":"https://github.com/rickiepark/handson-ml2/blob/master/07_ensemble_learning_and_random_forests.ipynb","timestamp":1605694258014}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"Zc6KCO1X1ZDZ"},"source":["**7장 – 앙상블 학습과 랜덤 포레스트**"]},{"cell_type":"markdown","metadata":{"id":"ojaRtZYH1ZDa"},"source":["_이 노트북은 7장에 있는 모든 샘플 코드와 연습문제 해답을 가지고 있습니다._"]},{"cell_type":"markdown","metadata":{"id":"hvQ9V5Qe1ZDa"},"source":["<table align=\"left\">\n","  <td>\n","    <a target=\"_blank\" href=\"https://colab.research.google.com/github/rickiepark/handson-ml2/blob/master/07_ensemble_learning_and_random_forests.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩에서 실행하기</a>\n","  </td>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"SAP67Yb91ZDm"},"source":["## 8. 투표 기반 분류기"]},{"cell_type":"markdown","metadata":{"id":"r2n5TuVX1ZDm"},"source":["문제: _MNIST 데이터를 불러들여 훈련 세트, 검증 세트, 테스트 세트로 나눕니다(예를 들면 훈련에 40,000개 샘플, 검증에 10,000개 샘플, 테스트에 10,000개 샘플)._"]},{"cell_type":"markdown","metadata":{"id":"VWmYpgzF1ZDm"},"source":["MNIST 데이터셋은 앞에서 로드했습니다."]},{"cell_type":"code","metadata":{"id":"ryntjraF1ZDm"},"source":["from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WAQ-QtAx1ZDm"},"source":["X_train_val, X_test, y_train_val, y_test = train_test_split(\n","    mnist.data, mnist.target, test_size=10000, random_state=42)\n","X_train, X_val, y_train, y_val = train_test_split(\n","    X_train_val, y_train_val, test_size=10000, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2yO2tl961ZDm"},"source":["문제: _그런 다음 랜덤 포레스트 분류기, 엑스트라 트리 분류기, SVM 같은 여러 종류의 분류기를 훈련시킵니다._"]},{"cell_type":"code","metadata":{"id":"FZBkFbk41ZDm"},"source":["from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n","from sklearn.svm import LinearSVC\n","from sklearn.neural_network import MLPClassifier"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R-xVfG3Z1ZDm"},"source":["random_forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n","extra_trees_clf = ExtraTreesClassifier(n_estimators=100, random_state=42)\n","svm_clf = LinearSVC(random_state=42)\n","mlp_clf = MLPClassifier(random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-HsOpI6W1ZDm","outputId":"88d457ea-a795-492a-cd24-ac1b4eb91e86"},"source":["estimators = [random_forest_clf, extra_trees_clf, svm_clf, mlp_clf]\n","for estimator in estimators:\n","    print(\"Training the\", estimator)\n","    estimator.fit(X_train, y_train)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training the RandomForestClassifier(random_state=42)\n","Training the ExtraTreesClassifier(random_state=42)\n","Training the LinearSVC(random_state=42)\n"],"name":"stdout"},{"output_type":"stream","text":["/home/haesun/anaconda3/envs/homl2/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Training the MLPClassifier(random_state=42)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3wvWOv8Y1ZDm","outputId":"118a2b80-5e63-4398-d70f-8184e2df9bb9"},"source":["[estimator.score(X_val, y_val) for estimator in estimators]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.9692, 0.9715, 0.8695, 0.9639]"]},"metadata":{"tags":[]},"execution_count":61}]},{"cell_type":"markdown","metadata":{"id":"qBb9dkWE1ZDn"},"source":["선형 SVM이 다른 분류기보다 성능이 많이 떨어집니다. 그러나 투표 기반 분류기의 성능을 향상시킬 수 있으므로 그대로 두겠습니다."]},{"cell_type":"markdown","metadata":{"id":"rR3NqTZ01ZDn"},"source":["문제: _그리고 검증 세트에서 개개의 분류기보다 더 높은 성능을 내도록 이들을 간접 또는 직접 투표 분류기를 사용하는 앙상블로 연결해보세요._"]},{"cell_type":"code","metadata":{"id":"21zyE3gY1ZDn"},"source":["from sklearn.ensemble import VotingClassifier"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rvwuUDhh1ZDn"},"source":["named_estimators = [\n","    (\"random_forest_clf\", random_forest_clf),\n","    (\"extra_trees_clf\", extra_trees_clf),\n","    (\"svm_clf\", svm_clf),\n","    (\"mlp_clf\", mlp_clf),\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2C9OyKVr1ZDn"},"source":["voting_clf = VotingClassifier(named_estimators)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lDHwa77z1ZDn","outputId":"4a2c2c34-1804-4ef0-da3f-5dcf1422e460"},"source":["voting_clf.fit(X_train, y_train)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/home/haesun/anaconda3/envs/homl2/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["VotingClassifier(estimators=[('random_forest_clf',\n","                              RandomForestClassifier(random_state=42)),\n","                             ('extra_trees_clf',\n","                              ExtraTreesClassifier(random_state=42)),\n","                             ('svm_clf', LinearSVC(random_state=42)),\n","                             ('mlp_clf', MLPClassifier(random_state=42))])"]},"metadata":{"tags":[]},"execution_count":65}]},{"cell_type":"code","metadata":{"id":"6f_MVoq61ZDn","outputId":"ae9ff104-84ad-4935-e46b-0595f0bc3164"},"source":["voting_clf.score(X_val, y_val)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9706"]},"metadata":{"tags":[]},"execution_count":66}]},{"cell_type":"code","metadata":{"id":"yUaA6vq61ZDn","outputId":"4475790a-5767-4260-cac6-764adc94fad8"},"source":["[estimator.score(X_val, y_val) for estimator in voting_clf.estimators_]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.9692, 0.9715, 0.8695, 0.9639]"]},"metadata":{"tags":[]},"execution_count":67}]},{"cell_type":"markdown","metadata":{"id":"LUV51blj1ZDn"},"source":["SVM 모델을 제거해서 성능이 향상되는지 확인해 보죠. 다음과 같이 `set_params()`를 사용하여 `None`으로 지정하면 특정 예측기를  제외시킬 수 있습니다:"]},{"cell_type":"code","metadata":{"id":"N1LH9FQu1ZDn","outputId":"e7e435b6-3d26-4b9f-c732-c00bf8c9b86b"},"source":["voting_clf.set_params(svm_clf=None)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["VotingClassifier(estimators=[('random_forest_clf',\n","                              RandomForestClassifier(random_state=42)),\n","                             ('extra_trees_clf',\n","                              ExtraTreesClassifier(random_state=42)),\n","                             ('svm_clf', None),\n","                             ('mlp_clf', MLPClassifier(random_state=42))])"]},"metadata":{"tags":[]},"execution_count":68}]},{"cell_type":"markdown","metadata":{"id":"X6cxYteH1ZDo"},"source":["예측기 목록이 업데이트되었습니다:"]},{"cell_type":"code","metadata":{"id":"L9UNg2UR1ZDo","outputId":"f2da13c2-69f9-408c-868a-a89b8e3909ae"},"source":["voting_clf.estimators"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('random_forest_clf', RandomForestClassifier(random_state=42)),\n"," ('extra_trees_clf', ExtraTreesClassifier(random_state=42)),\n"," ('svm_clf', None),\n"," ('mlp_clf', MLPClassifier(random_state=42))]"]},"metadata":{"tags":[]},"execution_count":69}]},{"cell_type":"markdown","metadata":{"id":"Z4CbcNe01ZDo"},"source":["하지만 훈련된 예측기 목록은 업데이트되지 않습니다:"]},{"cell_type":"code","metadata":{"id":"CW_1DFoB1ZDo","outputId":"1ff6257e-17f9-42fe-8890-fd2293f8c39d"},"source":["voting_clf.estimators_"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[RandomForestClassifier(random_state=42),\n"," ExtraTreesClassifier(random_state=42),\n"," LinearSVC(random_state=42),\n"," MLPClassifier(random_state=42)]"]},"metadata":{"tags":[]},"execution_count":70}]},{"cell_type":"markdown","metadata":{"id":"SKtLLLZR1ZDo"},"source":["`VotingClassifier`를 다시 훈련시키거나 그냥 훈련된 예측기 목록에서 SVM 모델을 제거할 수 있습니다:"]},{"cell_type":"code","metadata":{"id":"9fclU1NP1ZDo"},"source":["del voting_clf.estimators_[2]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d-x3SSi71ZDo"},"source":["`VotingClassifier`를 다시 평가해 보죠:"]},{"cell_type":"code","metadata":{"id":"FIMB47x11ZDo","outputId":"533106da-1dce-472b-c81a-ea2678b412fd"},"source":["voting_clf.score(X_val, y_val)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9736"]},"metadata":{"tags":[]},"execution_count":72}]},{"cell_type":"markdown","metadata":{"id":"mfhMXR4p1ZDo"},"source":["훨씬 나아졌네요! SVM 모델이 성능을 저하시켰습니다. 이제 간접 투표 분류기를 사용해 보죠. 분류기를 다시 훈련시킬 필요는 없고 `voting`을 `\"soft\"`로 지정하면 됩니다:"]},{"cell_type":"code","metadata":{"id":"dyr5OLyP1ZDp"},"source":["voting_clf.voting = \"soft\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L-GZQj1N1ZDp","outputId":"a200889f-84da-4942-ce7b-32da56d13b3a"},"source":["voting_clf.score(X_val, y_val)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.97"]},"metadata":{"tags":[]},"execution_count":74}]},{"cell_type":"markdown","metadata":{"id":"o6dM3CoZ1ZDp"},"source":["이 경우는 직접 투표 방식이 낫네요."]},{"cell_type":"markdown","metadata":{"id":"9QWfpPKi1ZDp"},"source":["_앙상블을 얻고 나면 테스트 세트로 확인해보세요. 개개의 분류기와 비교해서 성능이 얼마나 향상되나요?_"]},{"cell_type":"code","metadata":{"id":"g4rpkw4Z1ZDp","outputId":"8599109f-9f12-4910-fd80-cef0bd3db3e1"},"source":["voting_clf.voting = \"hard\"\n","voting_clf.score(X_test, y_test)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9704"]},"metadata":{"tags":[]},"execution_count":75}]},{"cell_type":"code","metadata":{"id":"nibFBY3Y1ZDp","outputId":"559c368e-fff9-4768-b7fd-cd9e6ac930c8"},"source":["[estimator.score(X_test, y_test) for estimator in voting_clf.estimators_]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.9645, 0.9691, 0.9604]"]},"metadata":{"tags":[]},"execution_count":76}]},{"cell_type":"markdown","metadata":{"id":"TVY6l4Sn1ZDp"},"source":["여기서는 투표 기반 분류기가 최선의 모델의 오차율을 아주 조금만 감소시킵니다."]},{"cell_type":"markdown","metadata":{"id":"QRl7baq-1ZDq"},"source":["문제: _이전 연습문제의 각 분류기를 실행해서 검증 세트에서 예측을 만들고 그 결과로 새로운 훈련 세트를 만들어보세요. 각 훈련 샘플은 하나의 이미지에 대한 전체 분류기의 예측을 담은 벡터고 타깃은 이미지의 클래스입니다. 새로운 훈련 세트에 분류기 하나를 훈련시켜 보세요._"]},{"cell_type":"code","metadata":{"id":"D1eeuMU71ZDr"},"source":["X_val_predictions = np.empty((len(X_val), len(estimators)), dtype=np.float32)\n","\n","for index, estimator in enumerate(estimators):\n","    X_val_predictions[:, index] = estimator.predict(X_val)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vm_Ht7W41ZDr","outputId":"a13d37f6-6f5f-488c-8983-2c91108a1edf"},"source":["X_val_predictions"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[5., 5., 5., 5.],\n","       [8., 8., 8., 8.],\n","       [2., 2., 2., 2.],\n","       ...,\n","       [7., 7., 7., 7.],\n","       [6., 6., 6., 6.],\n","       [7., 7., 7., 7.]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":78}]},{"cell_type":"code","metadata":{"id":"H0zo5yIX1ZDr","outputId":"1546b6a1-2aeb-4044-e86b-209da65f6f63"},"source":["rnd_forest_blender = RandomForestClassifier(n_estimators=200, oob_score=True, random_state=42)\n","rnd_forest_blender.fit(X_val_predictions, y_val)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RandomForestClassifier(n_estimators=200, oob_score=True, random_state=42)"]},"metadata":{"tags":[]},"execution_count":79}]},{"cell_type":"code","metadata":{"id":"woL9UdAD1ZDr","outputId":"1ff9a393-a883-4817-e93d-05f754306436"},"source":["rnd_forest_blender.oob_score_"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9677"]},"metadata":{"tags":[]},"execution_count":80}]},{"cell_type":"markdown","metadata":{"id":"wFVnZlTi1ZDr"},"source":["이 블렌더를 세밀하게 튜닝하거나 다른 종류의 블렌더(예를 들어, `MLPClassifier`)를 시도해 볼 수 있습니다. 그런 늘 하던대로 다음 교차 검증을 사용해 가장 좋은 것을 선택합니다."]},{"cell_type":"markdown","metadata":{"id":"dnKo8TvI1ZDr"},"source":["문제: _축하합니다. 방금 블렌더를 훈련시켰습니다. 그리고 이 분류기를 모아서 스태킹 앙상블을 구성했습니다. 이제 테스트 세트에 앙상블을 평가해보세요. 테스트 세트의 각 이미지에 대해 모든 분류기로 예측을 만들고 앙상블의 예측 결과를 만들기 위해 블렌더에 그 예측을 주입합니다. 앞서 만든 투표 분류기와 비교하면 어떤가요?_"]},{"cell_type":"code","metadata":{"id":"KZNJlP-V1ZDr"},"source":["X_test_predictions = np.empty((len(X_test), len(estimators)), dtype=np.float32)\n","\n","for index, estimator in enumerate(estimators):\n","    X_test_predictions[:, index] = estimator.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K1iwtnZh1ZDr"},"source":["y_pred = rnd_forest_blender.predict(X_test_predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l7cjPLLh1ZDr"},"source":["from sklearn.metrics import accuracy_score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BqHBR34o1ZDr","outputId":"e2bf8c2c-a689-4d9f-b371-6029989b4ce0"},"source":["accuracy_score(y_test, y_pred)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.967"]},"metadata":{"tags":[]},"execution_count":84}]},{"cell_type":"markdown","metadata":{"id":"uaNzCHMh1ZDr"},"source":["이 스태킹 앙상블은 앞서 만든 투표 기반 분류기만큼 성능을 내지는 못합니다. 최선의 개별 분류기만큼 뛰어나지는 않습니다."]}]}